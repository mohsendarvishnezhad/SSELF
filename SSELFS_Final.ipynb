{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujwBpvBskAoH"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the .mat file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Now the file is available in the current working directory\n",
        "mat_path = \"Data.mat\"  # Example file name, change to your file name"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "mat_path_gtm = \"GTM.mat\""
      ],
      "metadata": {
        "id": "zCmM-SEbkBKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import scipy.io as sio\n",
        "import time\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from sklearn.svm import SVC\n",
        "from torch.utils.data import Sampler\n",
        "# --------------------------\n",
        "# 1. Generate Synthetic HSI Data\n",
        "# --------------------------\n",
        "\n",
        "# Load HSI data and ground truth map\n",
        "data = scipy.io.loadmat('Data.mat')\n",
        "gtm = scipy.io.loadmat('GTM.mat')\n",
        "\n",
        "hsi = data['Data']  # Hyperspectral image data\n",
        "gt = gtm['GTM']  # Ground truth map\n",
        "\n",
        "# Display one band of HSI data (e.g., Band 1)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(hsi[:, :, 0], cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.title(\"HSI Band 1\")\n",
        "plt.show()\n",
        "\n",
        "# Display the GTM\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(gt, cmap='jet')  # 'jet' provides better visualization for categorical data\n",
        "plt.colorbar()  # Add a color legend\n",
        "plt.title(\"Ground Truth Map (GTM)\")\n",
        "plt.show()\n",
        "\n",
        "# --------------------------\n",
        "# 2. Patch Extraction and Preprocessing\n",
        "# --------------------------\n",
        "def extract_patch(hsi, center, patch_size=32):\n",
        "    \"\"\"Extract a cube patch from the HSI given the center and patch size.\"\"\"\n",
        "    h, w, _ = hsi.shape\n",
        "    half = patch_size // 2\n",
        "    c_i, c_j = center\n",
        "    # Limit to image boundaries\n",
        "    start_i = max(c_i - half, 0)\n",
        "    end_i = min(c_i + half, h)\n",
        "    start_j = max(c_j - half, 0)\n",
        "    end_j = min(c_j + half, w)\n",
        "    patch = hsi[start_i:end_i, start_j:end_j, :]\n",
        "    # If patch size is less than required, pad it\n",
        "    if patch.shape[0] < patch_size or patch.shape[1] < patch_size:\n",
        "        patch = cv2.copyMakeBorder(patch,\n",
        "                                   top=half - (c_i - start_i),\n",
        "                                   bottom=half - (end_i - c_i),\n",
        "                                   left=half - (c_j - start_j),\n",
        "                                   right=half - (end_j - c_j),\n",
        "                                   borderType=cv2.BORDER_REFLECT)\n",
        "    return patch\n",
        "\n",
        "def apply_pca(patch, n_components=3):\n",
        "    \"\"\"Apply PCA to reduce the spectral dimension of the patch to n_components.\"\"\"\n",
        "    h, w, bands = patch.shape\n",
        "    patch_2d = patch.reshape(-1, bands)\n",
        "    pca = PCA(n_components=n_components)\n",
        "    patch_reduced = pca.fit_transform(patch_2d)\n",
        "    patch_reduced = patch_reduced.reshape(h, w, n_components)\n",
        "    # Normalize to [0, 1]\n",
        "    patch_reduced = (patch_reduced - patch_reduced.min()) / (patch_reduced.max() - patch_reduced.min() + 1e-8)\n",
        "    return patch_reduced\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 3. Data Augmentation for Generating Two Views\n",
        "# --------------------------\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomCrop(28),  # Crop to a smaller size\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "def generate_two_views(patch):\n",
        "    \"\"\"\n",
        "    Generate two different augmented views from the input patch (numpy array).\n",
        "    The patch is assumed to be PCA-reduced and then augmented.\n",
        "    \"\"\"\n",
        "    patch_uint8 = (patch * 255).astype(np.uint8)\n",
        "    view1 = data_transforms(patch_uint8)\n",
        "    view2 = data_transforms(patch_uint8)\n",
        "    return view1, view2\n",
        "\n",
        "# --------------------------\n",
        "# 4. Calculate Difficulty of Each Patch\n",
        "# --------------------------\n",
        "\n",
        "\n",
        "# Function to calculate difficulty for a single pixel based on the provided formula\n",
        "def calculate_pixel_difficulty(H_i, alpha_i):\n",
        "    # Calculate difficulty using the formula\n",
        "    difficulty = np.sqrt(H_i**2 + (1 - np.abs((alpha_i - 60) / 60))**2)\n",
        "    return difficulty\n",
        "\n",
        "# Function to calculate difficulty for the entire patch\n",
        "def calculate_patch_difficulty(patch):\n",
        "    height, width, _ = patch.shape\n",
        "    difficulties = []\n",
        "\n",
        "    # Loop through every pixel in the patch\n",
        "    for i in range(height):\n",
        "        for j in range(width):\n",
        "            # Get H_i from the first band (H_i is the value at the first band of the pixel)\n",
        "            H_i = patch[i, j, 0]  # Value from the first band (H_i)\n",
        "\n",
        "            # Get alpha_i from the second band (alpha_i is the value at the second band of the pixel)\n",
        "            alpha_i = patch[i, j, 1]  # Value from the second band (α_i)\n",
        "\n",
        "            # Calculate difficulty for this pixel\n",
        "            pixel_difficulty = calculate_pixel_difficulty(H_i, alpha_i)\n",
        "            difficulties.append(pixel_difficulty)\n",
        "\n",
        "    # Calculate the average difficulty for the patch\n",
        "    patch_difficulty = np.mean(difficulties)\n",
        "    return patch_difficulty\n",
        "\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 6. Self-Supervised Dataset Definition\n",
        "# --------------------------\n",
        "\n",
        "class HSISelfSupervisedFullDataset(Dataset):\n",
        "    def __init__(self, hsi, patch_size=32):\n",
        "        \"\"\"\n",
        "        Extract patches from the entire HSI image, one for each pixel.\n",
        "        \"\"\"\n",
        "        self.hsi = hsi\n",
        "        self.patch_size = patch_size\n",
        "        self.height, self.width, _ = hsi.shape\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return total number of pixels in the image\n",
        "        return self.height * self.width\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Convert the 1D index to 2D coordinates (i, j)\n",
        "        i = idx // self.width\n",
        "        j = idx % self.width\n",
        "        center = (i, j)\n",
        "\n",
        "        # Extract a patch centered at (i, j)\n",
        "        patch = extract_patch(self.hsi, center, self.patch_size)\n",
        "        # Apply PCA to reduce spectral bands to 3 for compatibility with EfficientNet-B0\n",
        "        patch_pca = apply_pca(patch, n_components=3)\n",
        "        # Generate two different augmented views of the patch\n",
        "        view1, view2 = generate_two_views(patch_pca)\n",
        "        return view1, view2\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 7. Deep Curriculum Algorthm\n",
        "# --------------------------\n",
        "\n",
        "class CurriculumBatchSampler(Sampler):\n",
        "    def __init__(self, difficulties, batch_size):\n",
        "        \"\"\"\n",
        "        A sampler that generates batches ordered from easy to hard based on difficulty scores.\n",
        "\n",
        "        Args:\n",
        "            difficulties (list or array): Difficulty score for each sample (lower = easier).\n",
        "            batch_size (int): Number of samples in each mini-batch.\n",
        "        \"\"\"\n",
        "        self.difficulties = np.array(difficulties)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Sort all sample indices based on difficulty (easy to hard)\n",
        "        self.sorted_indices = np.argsort(self.difficulties)\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"\n",
        "        Yield batches in curriculum learning order: easy to hard.\n",
        "        \"\"\"\n",
        "        for i in range(0, len(self.sorted_indices), self.batch_size):\n",
        "            batch = self.sorted_indices[i:i + self.batch_size]\n",
        "            # Sort each batch internally by difficulty (just to be sure)\n",
        "            batch = sorted(batch, key=lambda idx: self.difficulties[idx])\n",
        "            yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Total number of batches.\n",
        "        \"\"\"\n",
        "        return (len(self.sorted_indices) + self.batch_size - 1) // self.batch_size\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 8. Define the ES2FL Model Based on EfficientNet-B0\n",
        "# --------------------------\n",
        "\n",
        "class ES2FLModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ES2FLModel, self).__init__()\n",
        "\n",
        "        # Load EfficientNet-B0 from torch.hub (no pretrained weights)\n",
        "        self.backbone = torch.hub.load('rwightman/gen-efficientnet-pytorch', 'efficientnet_b0', pretrained=False)\n",
        "\n",
        "        # Extract the stem (initial conv + BN + activation)\n",
        "        self.stem = nn.Sequential(\n",
        "            self.backbone.conv_stem,\n",
        "            self.backbone.bn1,\n",
        "            self.backbone.act1\n",
        "        )\n",
        "\n",
        "        # Extract the first 10 MBConv blocks\n",
        "        self.blocks = nn.Sequential(*self.backbone.blocks[:10])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)        # Converts input from 3 channels → 32 channels\n",
        "        x = self.blocks(x)      # Passes through first 10 MBConv blocks\n",
        "        x = torch.flatten(x, start_dim=1)  # Flatten from [B, C, H, W] to [B, C*H*W]\n",
        "        return x\n",
        "\n",
        "# --------------------------\n",
        "# 9. Self-Supervised Loss Function\n",
        "# --------------------------\n",
        "def self_supervised_loss(z_a, z_b, lambd=0.005):\n",
        "    \"\"\"\n",
        "    Compute the self-supervised loss:\n",
        "      L = sum_i (1 - C_ii)^2 + λ * sum_{i≠j} C_ij^2\n",
        "    where C is the cross-correlation matrix between two feature sets.\n",
        "    \"\"\"\n",
        "    batch_size, feat_dim = z_a.shape\n",
        "    # Compute cross-correlation matrix\n",
        "    c = torch.mm(z_a.T, z_b) / batch_size  # Shape: (feat_dim, feat_dim)\n",
        "\n",
        "    # Diagonal loss: make diagonal values close to 1\n",
        "    on_diag = torch.diagonal(c).add(-1).pow(2).sum()\n",
        "    # Off-diagonal loss: make off-diagonal values close to 0\n",
        "    off_diag = (c - torch.diag(torch.diagonal(c))).pow(2).sum()\n",
        "\n",
        "    loss = on_diag + lambd * off_diag\n",
        "    return loss\n",
        "\n",
        "# --------------------------\n",
        "# 10. Self-Supervised Training Function\n",
        "# --------------------------\n",
        "\n",
        "\n",
        "def train_with_cumulative_curriculum(patches, difficulties, batch_size, model, optimizer, device, epoch, total_epochs):\n",
        "    import random\n",
        "    model.train()\n",
        "\n",
        "    # Shuffle indices at the beginning of each epoch\n",
        "    indices = list(range(len(patches)))\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    # Divide into random batches\n",
        "    batches = [indices[i:i + batch_size] for i in range(0, len(indices), batch_size)]\n",
        "\n",
        "    # Compute average difficulty for each batch\n",
        "    batch_difficulties = [np.mean([difficulties[idx] for idx in batch]) for batch in batches]\n",
        "\n",
        "    # Sort batches based on their average difficulty (ascending)\n",
        "    sorted_batch_indices = np.argsort(batch_difficulties)\n",
        "\n",
        "    cumulative_indices = []\n",
        "    for iteration, batch_idx in enumerate(sorted_batch_indices, 1):\n",
        "        # Add current batch to cumulative list\n",
        "        cumulative_indices.extend(batches[batch_idx])\n",
        "\n",
        "        # Prepare current cumulative batch\n",
        "        selected_patches = [patches[i] for i in cumulative_indices]\n",
        "        views1, views2 = zip(*selected_patches)\n",
        "        views1, views2 = torch.stack(views1).to(device), torch.stack(views2).to(device)\n",
        "\n",
        "        # Training step\n",
        "        optimizer.zero_grad()\n",
        "        z_a = model(views1)\n",
        "        z_b = model(views2)\n",
        "        loss = self_supervised_loss(z_a, z_b, lambd=0.005)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch}/{total_epochs}] Iteration [{iteration}/{len(batches)}] Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 11. Feature Extraction and Classification (Using Random Forest as Example)\n",
        "# --------------------------\n",
        "def extract_features(model, hsi, patch_size=32, centers=None, device='cuda'):\n",
        "    \"\"\"\n",
        "    Extract deep features for specified pixel centers.\n",
        "    centers: list of tuples (i, j)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    features_list = []\n",
        "    with torch.no_grad():\n",
        "        for center in centers:\n",
        "            patch = extract_patch(hsi, center, patch_size)\n",
        "            patch_pca = apply_pca(patch, n_components=3)\n",
        "            # Convert to tensor and apply necessary transforms\n",
        "            patch_tensor = transforms.ToTensor()( (patch_pca*255).astype(np.uint8) ).unsqueeze(0).to(device)\n",
        "            feat = model(patch_tensor)\n",
        "            feat = feat.cpu().numpy().flatten()\n",
        "            features_list.append(feat)\n",
        "    return np.array(features_list)\n",
        "\n",
        "def extract_spectral_vector(hsi, center):\n",
        "    \"\"\"Return the spectral vector at the given center pixel.\"\"\"\n",
        "    i, j = center\n",
        "    spectral_vec = hsi[i, j, :]\n",
        "    return spectral_vec\n",
        "\n",
        "def get_labeled_centers(gt, samples_per_class=5, num_classes=5, seed=42):\n",
        "    \"\"\"Randomly select labeled centers (pixels) for each class.\"\"\"\n",
        "    random.seed(seed)\n",
        "    centers = []\n",
        "    labels = []\n",
        "    h, w = gt.shape\n",
        "    for cls in range(num_classes):\n",
        "        cls_indices = np.argwhere(gt == cls)\n",
        "        selected = random.sample(cls_indices.tolist(), samples_per_class)\n",
        "        for s in selected:\n",
        "            centers.append(tuple(s))\n",
        "            labels.append(cls)\n",
        "    return centers, np.array(labels)\n",
        "\n",
        "# --------------------------\n",
        "# 12. Spectral Features\n",
        "# --------------------------\n",
        "\n",
        "def extract_raw_spectral_features(hsi_subset, centers):\n",
        "    \"\"\"\n",
        "    Extract raw spectral features (direct pixel values) from the given HSI subset\n",
        "    at specified spatial centers.\n",
        "\n",
        "    Parameters:\n",
        "        hsi_subset (np.ndarray): HSI data for one spectral group [H, W, bands].\n",
        "        centers (list of tuples): List of (i, j) spatial coordinates.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array of shape [num_samples, num_bands] with spectral vectors.\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    for i, j in centers:\n",
        "        features.append(hsi_subset[i, j, :])\n",
        "    return np.array(features)\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 13. Padding Array\n",
        "# --------------------------\n",
        "\n",
        "def apply_padding(features, patch=3):\n",
        "    \"\"\"\n",
        "    Apply padding to the feature vector to convert it to a 2D matrix.\n",
        "\n",
        "    features: 1D array of features (feature_dim,)\n",
        "    patch_size: Size of the patch (3x3 for example, resulting in a 3x3 matrix)\n",
        "\n",
        "    Returns: 2D matrix (patch_size x patch_size x feature_dim)\n",
        "    \"\"\"\n",
        "    # Get the dimension of the feature vector\n",
        "    feature_dim = features.shape[0]  # Should be 1024 for example\n",
        "\n",
        "    # Initialize a zero matrix for the padded features\n",
        "    padded_features = np.zeros((patch, patch, feature_dim))  # Initialize a zero matrix\n",
        "\n",
        "    # Fill the center of the patch with the features\n",
        "    padded_features[patch // 2, patch // 2, :] = features  # Place feature vector in the center\n",
        "    return padded_features\n",
        "\n",
        "# Applying padding on the combined features:\n",
        "def apply_padding_to_features(features_list, patch=3):\n",
        "    \"\"\"\n",
        "    Apply padding to all features in the list and return the padded features.\n",
        "\n",
        "    features_list: List of feature vectors (N x feature_dim)\n",
        "    patch_size: Size of the patch (3x3 for example)\n",
        "\n",
        "    Returns: List of padded feature matrices (N x patch_size x patch_size x feature_dim)\n",
        "    \"\"\"\n",
        "    padded_features_list = []\n",
        "\n",
        "    for features in features_list:\n",
        "        padded_features = apply_padding(features, patch)\n",
        "        padded_features_list.append(padded_features)\n",
        "\n",
        "    return np.array(padded_features_list)\n",
        "\n",
        "\n",
        "# --------------------------------\n",
        "# 14. Local Bainary Graph Algorithm\n",
        "# --------------------------------\n",
        "\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.linalg import eigh\n",
        "\n",
        "def build_graph_matrix(patch_reshaped, k=4):\n",
        "    \"\"\"\n",
        "    Constructs adjacency matrix A using k-nearest neighbors based on Euclidean distance.\n",
        "    :param patch_reshaped: numpy array of shape (N, C), where N is number of pixels and C is number of spectral bands\n",
        "    :param k: number of nearest neighbors\n",
        "    :return: adjacency matrix A of shape (N, N)\n",
        "    \"\"\"\n",
        "    N = patch_reshaped.shape[0]\n",
        "\n",
        "    # Compute Euclidean distance between all pixel vectors\n",
        "    distances = cdist(patch_reshaped, patch_reshaped, metric='euclidean')\n",
        "\n",
        "    # For each pixel, keep only k nearest neighbors (excluding self)\n",
        "    A = np.zeros((N, N))\n",
        "    for i in range(N):\n",
        "        idx = np.argsort(distances[i])[1:k+1]  # Skip self (0th index)\n",
        "        A[i, idx] = 1\n",
        "        A[idx, i] = 1  # Make it symmetric\n",
        "\n",
        "    return A\n",
        "\n",
        "def compute_degree_matrix(A):\n",
        "    \"\"\"\n",
        "    Constructs diagonal degree matrix D from adjacency matrix A.\n",
        "    :param A: adjacency matrix of shape (N, N)\n",
        "    :return: degree matrix D of shape (N, N)\n",
        "    \"\"\"\n",
        "    D = np.diag(np.sum(A, axis=1))\n",
        "    return D\n",
        "\n",
        "def compute_laplacian(D, A):\n",
        "    \"\"\"\n",
        "    Computes unnormalized graph Laplacian matrix L = D - A.\n",
        "    :param D: degree matrix\n",
        "    :param A: adjacency matrix\n",
        "    :return: Laplacian matrix L\n",
        "    \"\"\"\n",
        "    return D - A\n",
        "\n",
        "def compute_feature_fusion(patch, output_channels=40, k=4):\n",
        "    \"\"\"\n",
        "    Applies graph-based feature fusion on a given patch.\n",
        "    :param patch: numpy array of shape (H, W, C)\n",
        "    :param output_channels: number of output fused spectral dimensions\n",
        "    :param k: number of nearest neighbors in the graph\n",
        "    :return: fused features of shape (H*W, output_channels)\n",
        "    \"\"\"\n",
        "    H, W, C = patch.shape\n",
        "    N = H * W\n",
        "\n",
        "    # Step 1: Reshape patch to (N, C)\n",
        "    X = patch.reshape(N, C)\n",
        "\n",
        "    # Step 2: Construct graph adjacency matrix A\n",
        "    A = build_graph_matrix(X, k=k)\n",
        "\n",
        "    # Step 3: Compute degree matrix D\n",
        "    D = compute_degree_matrix(A)\n",
        "\n",
        "    # Step 4: Compute Laplacian matrix L = D - A\n",
        "    L = compute_laplacian(D, A)\n",
        "\n",
        "    # Step 5: Compute P = X^T * D * X\n",
        "    P = X.T @ D @ X  # Shape: (C, C)\n",
        "\n",
        "    # Regularization for numerical stability\n",
        "    epsilon = 1e-5\n",
        "    P += epsilon * np.eye(P.shape[0])\n",
        "\n",
        "    # Step 6: Compute Q = X^T * L * X\n",
        "    Q = X.T @ L @ X  # Shape: (C, C)\n",
        "\n",
        "    # Step 7: Solve generalized eigenvalue problem Qw = λPw\n",
        "    eigvals, eigvecs = eigh(Q, P)\n",
        "\n",
        "    # Step 8: Select top 'output_channels' eigenvectors (with largest eigenvalues)\n",
        "    sorted_idx = np.argsort(eigvals)[::-1]\n",
        "    top_eigvecs = eigvecs[:, sorted_idx[:output_channels]]  # Shape: (C, output_channels)\n",
        "\n",
        "    # Step 9: Multiply reshaped patch (N, C) with weight matrix (C, output_channels)\n",
        "    fused_features = X @ top_eigvecs  # Resulting shape: (N, output_channels)\n",
        "\n",
        "    return fused_features  # shape: (H*W, output_channels)\n",
        "\n",
        "def batch_feature_fusion(patches, output_channels=40, k=4):\n",
        "    \"\"\"\n",
        "    Applies graph-based feature fusion to a batch of patches.\n",
        "    :param patches: numpy array of shape (N, H, W, C)\n",
        "    :param output_channels: number of output spectral features\n",
        "    :param k: number of neighbors for graph construction\n",
        "    :return: numpy array of shape (N, H*W, output_channels)\n",
        "    \"\"\"\n",
        "    N, H, W, C = patches.shape\n",
        "    fused_batch = np.zeros((N, H * W, output_channels))\n",
        "\n",
        "    for i in range(N):\n",
        "        fused_batch[i] = compute_feature_fusion(patches[i], output_channels=output_channels, k=k)\n",
        "\n",
        "    return fused_batch\n",
        "\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 15. Main Function to Run the Entire Process\n",
        "# --------------------------\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Self-supervised training using full HSI\n",
        "    print(\"ِPatch Ranking Uisng The Deep Curriculum Learning Model Has Been Started\")\n",
        "    ss_dataset = HSISelfSupervisedFullDataset(hsi, patch_size=32)\n",
        "\n",
        "    # List of patches and their difficulty scores\n",
        "    patches = []\n",
        "    difficulties = []\n",
        "    print(f\" Number of Pathces: {len(ss_dataset)}\")\n",
        "\n",
        "    for idx in range(len(ss_dataset)):\n",
        "        view1, view2 = ss_dataset[idx]\n",
        "        patch = view1.numpy()  # For example, use view1 to compute difficulty\n",
        "        difficulty = calculate_patch_difficulty(patch)\n",
        "        # Print the calculated difficulty\n",
        "        # print(f\"Difficulty of the patch: {difficulty}\")\n",
        "        patches.append((view1, view2))\n",
        "        difficulties.append(difficulty)\n",
        "\n",
        "    # Neural Network Model : Efficent Net B0\n",
        "    model = ES2FLModel().to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    print(\"Training Process of The Efficientnet-B0 Using Our Proposed Method Has Been Started\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    epochs = 1\n",
        "    total_epochs = 1\n",
        "\n",
        "    for epoch in range(1, total_epochs + 1):\n",
        "\n",
        "      print(f\"Training Epoch {epoch}/{total_epochs}\")\n",
        "      model = train_with_cumulative_curriculum(patches=patches,\n",
        "        difficulties=difficulties,\n",
        "        batch_size=64,\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        device=device,\n",
        "        epoch=epoch,\n",
        "        total_epochs=total_epochs)\n",
        "\n",
        "    print(\"The Efficientnet-B0 Has been Trained\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    minutes = int(elapsed_time // 60)\n",
        "    seconds = int(elapsed_time % 60)\n",
        "    print(f\"Training completed in {minutes} minutes and {seconds} seconds\")\n",
        "\n",
        "    centers, labels = get_labeled_centers(gt, samples_per_class=5, num_classes=5)\n",
        "    all_centers = [(i, j) for i in range(hsi.shape[0]) for j in range(hsi.shape[1]) if gt[i, j] > 0]\n",
        "\n",
        "    patch_sizes = [32, 64]\n",
        "    final_ensemble_probs = None\n",
        "    total_weights = 0.0\n",
        "\n",
        "    print(\"Starting The Second Phase of The Proposed Method: Feature Level and View Level Ensemble Strategy\")\n",
        "\n",
        "    num_bands = hsi.shape[2]\n",
        "    band_mutual_info = np.zeros((num_bands, num_bands))\n",
        "\n",
        "    for i in range(num_bands):\n",
        "        for j in range(i+1, num_bands):\n",
        "            band_mutual_info[i, j] = mutual_info_score(hsi[:, :, i].flatten(), hsi[:, :, j].flatten())\n",
        "            band_mutual_info[j, i] = band_mutual_info[i, j]\n",
        "\n",
        "    print(\"Mutual information between bands calculated.\")\n",
        "\n",
        "    for band_idx in range(num_bands):\n",
        "        print(f\"Creating Group for Band {band_idx + 1} of {num_bands}\")\n",
        "\n",
        "        mutual_info_scores = band_mutual_info[band_idx]\n",
        "        sorted_band_indices = np.argsort(mutual_info_scores)[-20:]\n",
        "        group_bands = [band_idx] + sorted_band_indices.tolist()\n",
        "        print(f\"Group {band_idx+1}: {len(group_bands)} Spectral Features\")\n",
        "\n",
        "        hsi_subset = hsi[:, :, group_bands]\n",
        "\n",
        "        spectral_features = extract_raw_spectral_features(hsi_subset, centers)\n",
        "        all_spectral_features = extract_raw_spectral_features(hsi_subset, all_centers)\n",
        "\n",
        "        group_features_list = []\n",
        "        group_all_features_list = []\n",
        "\n",
        "        for ps in patch_sizes:\n",
        "            print(f\"View Level Ensemble: Patch Size {ps}\")\n",
        "\n",
        "            start_time = time.time()\n",
        "            features = extract_features(model, hsi_subset, patch_size=ps, centers=centers, device=device)\n",
        "            print(f\"Deep Features of {ps} Patch Size: {features.shape[-1]} Features\")\n",
        "            end_time = time.time()\n",
        "            minutes = int((end_time - start_time) // 60)\n",
        "            seconds = int((end_time - start_time) % 60)\n",
        "            print(f\"Feature Extraction Process In Training Phase For Patch Size {ps} and Group {band_idx + 1} Has Been Completed in {minutes} minutes and {seconds} seconds\")\n",
        "\n",
        "            group_features_list.append(features)\n",
        "\n",
        "            start_time = time.time()\n",
        "            all_features = extract_features(model, hsi_subset, patch_size=ps, centers=all_centers, device=device)\n",
        "            end_time = time.time()\n",
        "            minutes = int((end_time - start_time) // 60)\n",
        "            seconds = int((end_time - start_time) % 60)\n",
        "            print(f\"Feature Extraction Process In Test Phase For Patch Size {ps} and Group {band_idx + 1} Has Been Completed in {minutes} minutes and {seconds} seconds\")\n",
        "\n",
        "            group_all_features_list.append(all_features)\n",
        "\n",
        "        # Combine features from different patch sizes and spectral features\n",
        "        combined_features = np.concatenate(group_features_list + [spectral_features], axis=1)\n",
        "        combined_all_features = np.concatenate(group_all_features_list + [all_spectral_features], axis=1)\n",
        "        padded_combined_features = apply_padding_to_features(combined_features, patch=3)\n",
        "        print(padded_combined_features.shape)\n",
        "        padded_combined_all_features = apply_padding_to_features(combined_all_features, patch=3)\n",
        "        print(padded_combined_all_features.shape)\n",
        "\n",
        "        # Apply Local Graph-Based Fusion on the extracted features (combined_features and combined_all_features)\n",
        "        fused_features_train = []\n",
        "        fused_output_train = batch_feature_fusion(padded_combined_features, output_channels=40, k=4)\n",
        "        fused_features_train = np.array(fused_output_train)\n",
        "        print(\"Feature fusion for the train dataset has been completed.\")\n",
        "\n",
        "        print(f\"Fused Deep Features for Train Set: {fused_features_train.shape[-1]} Features\")\n",
        "\n",
        "        NN = fused_features_train.shape[0]\n",
        "        print(f\"N : {NN} Train Samples\")\n",
        "        fused_features_train = fused_features_train.reshape(NN, -1)\n",
        "\n",
        "        print(f\"Fused Deep Features for Train Set After Reshape: {fused_features_train.shape[-1]} Features\")\n",
        "\n",
        "        fused_all_features_test = []\n",
        "        fused_output_test = batch_feature_fusion(padded_combined_all_features, output_channels=40, k=4)\n",
        "        fused_all_features_test = np.array(fused_output_test)\n",
        "        print(\"Feature fusion for the test dataset has been completed.\")\n",
        "        # N = fused_all_features_test.shape[0]\n",
        "        NN = fused_all_features_test.shape[0]\n",
        "        print(f\"N : {NN} Test Samples\")\n",
        "        fused_all_features_test = fused_all_features_test.reshape(NN, -1)\n",
        "\n",
        "\n",
        "\n",
        "        # Train the SVM Classifier using the fused features\n",
        "        start_time = time.time()\n",
        "        clf = SVC(probability=True, kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
        "        clf.fit(fused_features_train, labels)\n",
        "        end_time = time.time()\n",
        "        minutes = int((end_time - start_time) // 60)\n",
        "        seconds = int((end_time - start_time) % 60)\n",
        "        print(f\"SVM Classifier Has Been Trained For Group {band_idx + 1} in {minutes} minutes and {seconds} seconds\")\n",
        "\n",
        "        probs = clf.predict_proba(fused_all_features_test)\n",
        "        print(f\"Test Phase For Group {band_idx + 1} Has Been Completed Using The SVM Classifier\")\n",
        "\n",
        "        true_labels = np.array([gt[i, j] for (i, j) in all_centers])\n",
        "        pred = clf.predict(fused_all_features_test)\n",
        "        acc = accuracy_score(true_labels, pred)\n",
        "        print(f\"[Group {band_idx + 1}/{num_bands}] Classification Accuracy: {acc:.4f}\")\n",
        "\n",
        "        weight = acc\n",
        "        total_weights += weight\n",
        "\n",
        "        if final_ensemble_probs is None:\n",
        "            final_ensemble_probs = probs * weight\n",
        "        else:\n",
        "            final_ensemble_probs += probs * weight\n",
        "\n",
        "    final_ensemble_probs /= total_weights\n",
        "    final_pred = np.argmax(final_ensemble_probs, axis=1)\n",
        "\n",
        "    classified_map = np.zeros(gt.shape, dtype=int)\n",
        "    valid_idx = np.argwhere(gt > 0)\n",
        "    for idx, (i, j) in enumerate(valid_idx):\n",
        "        classified_map[i, j] = final_pred[idx]\n",
        "\n",
        "    gt_flat = gt[gt > 0].flatten()\n",
        "    oa = accuracy_score(gt_flat, final_pred) * 100\n",
        "    conf_matrix = confusion_matrix(gt_flat, final_pred)\n",
        "    report = classification_report(gt_flat, final_pred)\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(report)\n",
        "    print(f\"Overall Accuracy (OA): {oa:.2f}%\")\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(classified_map, cmap='jet')\n",
        "    plt.colorbar()\n",
        "    plt.title(\"Ensemble Classification Map (Patch Sizes: 32, 64, 128)\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "id": "Cq8M0WVxkCHh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}